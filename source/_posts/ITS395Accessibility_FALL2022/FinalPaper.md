---
title: ITS395 Final Paper Proposal
date: December 15, 2022
tags:
  - Articles
  - Accessibility
categories: Accessibility Research

#阅读模式，右下角开启
readmode: true

#封面
cover: https://www.umaryland.edu/media/umb/cpa/accessibility/web-accessibility-page/accessibility.jpg

#版权
copyright_author: Zehui Liu
copyright_url: https://ahui9605.github.io/

description: ITS395 Final Paper Proposal
---

### Final Paper Idea

_Live Sign Interpreter Anywhere_

This is just a "pop-up" idea that I discussed in class on Thursday where I had already discussed it. It is basically a software or a plug-in that can be added to a web browser. The function is the interpreter can be toggled on and off at any time for people with disabilities who are having a negative experience or are having trouble gathering information on a computer or a television, such as watching a video or video chatting, reading a short article, or reading comments. The live time interpreter can appear in a small window in the lower-right corner of the screen and provide assistance to users at any time; alternatively, the window can be dragged to any location the user finds more convenient.

_Closed Interpreting Accessibility Revision_

A project in which I worked with my partner and two mentors on REU internship experiences during the summer. It is about how Sign Language Interpreters are not readily available on television or in online media. Our project offers an application programming interface (API) known as AblePlayer, and we made some modifications to this API in order to make it more supportive of features related to sign interpreters window. Considering that this project has already been completed, however, I would like to provide some revised feedbacks and make some alterations to the CIA concept. Therefore, I will eliminate some of the superfluous features, such as the transparency functions, and ensure that the sign interpreter windows do not have an excessive amount of transparency. I will also try to fix those bugs where they still existed right now.

_Web Browser Background Color_

The use of well-known web browsers such as Chrome, Firefox, and Edge have become an integral part of our daily lives. We rely on them on a daily basis to carry out both our productive and entertaining work. But for those individuals who suffer from a condition known as color sensitivity, which makes it uncomfortable for them to view backgrounds of black and white or a particular color. Even though some browsers provide a daytime and nighttime mode, the primary goal of this feature was originally to safeguard the eyes. So there is a tool that needs to be made public and utilized in order to assist those individuals who are color sensitive. A good idea could be to change the sensitive color set by the users, including the different website background, or a particular area for decoration, or even all images and diagrams. This would be an example of how this could be used. The sensitive color will be changed to an alternative color, but the other colors will remain unchanged.

### Based on Few Advices to Made Modifications on Able Player

#### Abstract

Sign Language in the media, either on-site or remotely, is provided to people who are Deaf and hard of hearing to be informed about critical information and other critical information in their daily lives. Access to Sign Language on TV or online media is not a requirement outlined within the ADA. . Deaf users are still using closed captions as their alternative options for watching TV and other media (Liu & Lam, 2022). To promote quality accessibility, my previous project developed Able Player (Liu & Lam, 2022), an accessible tool similar to closed captioning that will be displayed with an sign interpreter video that can be toggled on and off. This closed interpreting tool is user adjustable. It contains settings such as interpreter window size, transparency, and moveable window. All of which can be adjusted by the user. My project (Liu & Lam, 2022) received numerous feedback, such as some areas of the user interface design needing to be corrected, where I need to continue to work on more about this part, and some buttons needing more detail, some developers might want to use the API, because I made a lot of modifications on the original Able Player, so a manual is required in order to provide clear instructional guidelines for using the API. This study aims to evaluate the modified Able Player tool and provide a instructional manual how to use the API for the web developer. The IRB approval is still needed where it involves human research, and I will work with more if time permits after getting approval.

#### Introductoin

The utilization of accessibility has grown as a result of the fast development of high-speed transmission and video technology. Deaf and hard of hearing people are increasingly adapting to acquire information from television shows, films and websites. Thus, accessibility such as captions both in closed captions and open captions are become very important where deaf and hard of hearing people are rely on them as a very valuable tool for translating spoken language. (Liu & Lam, 2022). However, the captions as the major accessibility are still an “ad-hoc” for deaf and hard of hearing. One example is the YouTube Video where it was designed to those who speak, read and write English very well and it is only use as the alternative option to replace aural information to many deaf viewers and they find it very difficult to follow because the speed of verbatim captioning is likely to exceed their reading abilities . Even after controlling for reading level, deaf students learned less from on-screen text than hearing peers. They prefer ASL interpreters over closed captions, partially because they find captions difficult to understand and partly because they receive less information (Debevc et al., 2015).

I had another option where it provided the PIP (Picture in Picture)mode with the sign language interpreter on TV and internet vides. However, the media tends to crop out the screen of the interpreter if it is even available to all, which prevents the DHH viewer from getting full access to information. Providing PIP on a few channels or sources achieves critical mass, albeit with limited success. If not properly set up, it might be difficult for the deaf audience to see what is being spoken, resulting in incomplete communication. It only caters to the DHH community on a limited level, therefore this issue may be difficult for DHH individuals because the media is hearing-centric, and they have little experience with sign language translating on TV (Liu & Lam, 2022).

#### Methodology

The research will be split into two parts: one will concentrate on the user experience and user interface, while the other will be geared toward website developers. Both the user and the viewer will have a better experience watching content that is more accessible if a good instruction on how to utilize the Able Player API for website developers is provided. The steps outlined below are broken up into two parts. The first step is to write a manual, it will be referred to by the person responsible for developing the website in order to correctly configure and install the Able Player there. The second option is a modified version of Able Player, which has had bugs corrected and unnecessary functionalities removed allow user to watch without any problem.

_Able Player Manual:_
I created and participated on a project that offered a more accessible media player, called Able Player, and allowed users to use it whenever they wanted. However, there are still some problems with this project, so I made some improvements to the accessible media player to make it more user-friendly and accessible for everyone after the survey and Q&A interview session on that project. Additionally, I want to ensure that the web developers can use this encapsulated API to set up all of the functionality without any issues. Therefore, a detailed manual is necessary to utilize in order to expand on how to use the Able Player as needed.
The manual will be included:

- General instructions
- Purpose of making this modification
- The reference documents
- API environment requirements
- Assistance and problem reporting
- Common issues where developer encounters
- License

_Survey:_
I intend to get in touch with the previous participants who volunteered their time and see if they would be interested in coming back to try out my improved version of the Able Player. It is my expectation that there will be approximately two to three persons there, and that number will be sufficient for me. If there is enough time, I could ask one or two website developers to participate in this research study as new participants and then show them my API along with the manual that I just finished writing for the project. The survey will be use in Google Form and will be analyzed after the usability test done. It will include five multiple-choice questions, and respondents will be asked to rank each question on a scale from 1 to 5 based on the degree to which they agree with the statement that they are reading. Also, there will be a open-discussion Q&A that ask participants for their feedback regarding this project and the modification that I had been made.

#### Evaluation

It is intended that I will spend around ten minutes with each participant, explaining the various informed consent forms either in American Sign Language (ASL) or spoken English. They are going to be provided with a general explanation of the goal of this research.

I will supply each participant with a laptop, and they will all meet in a room individually. They are free to bring own computer. However, their computer must be capable of running Chrome Version 109.0.5xx or a later version, as well as Microsoft Edge Version 95.x or the most recent version. I will supply the pre-set Able Player with the videos that were used in the previous project, along with the American Sign Language interpreter. At this time, I will make it shorter by only requiring one video to watch from each participant, and the topic will be the same throughout. The video #3: Gas Price in Los Angeles from the previous project will be use to all participants in Figure 1:

![](/images/REU_CIA/CIA,figure2.png "Figure 1: Example of an Early Able Player Media Version")

Because I was not funded by any organization or funding support, none of the participants will receive any compensation for their time spent participating in the usability study. The replies of all participants in both the usability study and the survey were kept strictly confidential and were only meant to be discussed between the researcher I am working on this project.

#### Result

The approval of the IRB is a significant obstacle given that this study includes variables of human research. For now, I should wait to get the IRB approval to move forward with the evaluation and research test. From the Able Player itself in the survey from my previous project, a number of the participants reported that they had a favorable opinion of the media player use. We conducted our research with a total of 10 participants, and we utilized the same survey for each round of usability testing. In order to assess and present the results, we used an Excel chart generating tool to depict each participant's responses. The scores for individual participants and different hearing status groups of participants were examined shown in Figure 2, and the scores for most participants were medium-high level which is considering a great and useful media player to them.

![](/images/REU_CIA/CIA,figure3.1.png "Figure 2: A Chart of the System Usability Scale Calculation by Score")

#### Conclusion

Because the modified version of Able Player in version 1.0 received a great deal more positive feedback, I do expect to have a successful outcome with the modified version of Able Player. Also, I am unsure whether the web developer will find the handbook to be understandable or not. Therefore, I still require further time to figure out.

#### The Innovation of Speech English to Auto Generating Sign Language Interpreting

All sign interpreting is pre-recorded and prepared for usage in the Able Player or other media source in accordance with the WCAG 2.1 Guideline. However, where the WCAG does not include it with the auto-generating sign interpreting similar to the auto-generating captions.

When you want to make accessibility features for the DHH community, it is a big problem because you have to hire certified sign language interpreters and have video editing skills to ensure that the DHH audience has the best possible watching experience. If more videos are provided about the website's development, the budget might increase to a significant amount. The captions had the exact same problem in the very beginning stage, but thanks to improvements in closed captioning with more advanced technology, there are now captions that are automatically generated and support a variety of languages. It works with speech recognition technology, which enables the computer to listen like a human, generate captions, and display captions on screen.

The future will have high accuracy AI technology that can do anything a computer can. The idea is the same with sign interpreting as well because it serves the same purpose of translating speech English into another language. For instance, the official Chinese Central Television (CCTV) successfully used AI interpreting in 2021 in conjunction with Chinese sign language recognition with different recognition algorithm (Gao et al., 2022). I believe the future will use this concept of AI technology to create better DHH accessibility and the least amount of work possible for website developer without any additional process.

#### Future Works

There were technological concerns that necessitated the assistance of additional UI and UX professional consultants and specialists, such as incorporating a new design style on a dropdown menu. A professional can provide far more beneficial recommendations. While working on this enormous project since 2014, more than three or four individuals are also encouraged to contribute to the future development of Able Player. It is my expectation and encouragement that more people will use this Able Player tool to increase accessibility because it is a wonderful tool to use as needed requiring less work and develop time and also followed with the WCAG. I hope that more people will use this tool, and I will encourage them to do so.

Another significant problem that my project team ran into was the enormous amount of time required to work on the sign interpreting videos. I am expecting to wait for the concept of auto generating AI sign interpreting where they can release the open-source API that website developer can use it with support for American sign language. The amount of work can be significantly decreased.

#### References

<table>
    <tr>
        <td>Bosch-Baliarda, M., Soler-Vilageliu, O., & Orero, P. (2020). Sign language interpreting on TV: A reception study of visual screen exploration in deaf signing users. MonTI. Monografías De Traducción e Interpretación, (12), 108–143. https://doi.org/10.6035/monti.2020.12.04 
        </td>
    </tr>
        <tr>
        <td>Brooke, J. (1986). “SUS: a “quick and dirty” usability scale”. In P. W. Jordan, B. Thomas, B. A. Weerdmeester, & A. L. McClelland (eds.). Usability Evaluation in Industry. London: Taylor and Francis.
        </td>
    </tr>
        </tr>
        <tr>
        <td>Cronin, B. J. (2013, April 22). Chapter 14: Closed-caption television: Today and Tomorrow. American Annals of the Deaf. Retrieved June 7, 2022, from https://muse.jhu.edu/article/386799/pdf
        </td>
    </tr>
        </tr>
        <tr>
        <td>Debevc, M., Milošević, D., & Kožuh, I. (2015). A comparison of comprehension processes in sign language interpreter videos with or without captions. PLOS ONE, 10(5). https://doi.org/10.1371/journal.pone.0127577
        </td>
    </tr>
        </tr>
        </tr>
        <tr>
        <td>Gao, W., Chen, Y., Zhao, D., & Fang, G. (2022). A chinese sign language recognition system based on SOFM/SRN/HMM. Pattern Recognition. Retrieved December 11, 2022, from https://www.sciencedirect.com/science/article/abs/pii/S0031320304001657
        </td>
    </tr>
        </tr>
        </tr>
        <tr>
        <td>Huang, C.-wei. (2003). Automatic Closed Caption Alignment Based on Speech Recognition Transcript. CiteSeerX. Retrieved June 7, 2022, from http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.233.419
        </td>
    </tr>
        </tr>
        </tr>
        <tr>
        <td>Liu, Z., & Lam, B. (2022, July 28). Closed Interpreting Accessibility. Google Doc. Retrieved December 6, 2022, from https://docs.google.com/document/d/11iwfn-NgzxBQlD4kN6lwVBSclLsJ_B6Y1WJBZ0hNKTE/edit
        </td>
    </tr>
        </tr>
        </tr>
        <tr>
        <td>Yi, J. H., et al. (2021). Design Proposal for Sign Language Services in TV Broadcasting from the Perspective of People Who Are Deaf or Hard of Hearing. Applied Sciences, 11(23), 11211. https://doi.org/10.3390/app112311211
        </td>
    </tr>
</table>
